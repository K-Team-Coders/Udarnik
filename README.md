# Udarnik ![Логотип проекта](/frontend/Udarnik.png)

Доброго времени суток, всем кто это читает, вашему вниманию представляется распредленная система сбора и обработки сигналов экгаустеров агломерационой машины под кодовым названием  **Ударник**!
ВНИМАНИЕ! В целях экономии вычислительных ресурсов, а также в условия ограниченности времени используем данные только для одного эксгаустера (при этом предоставляем данный код для расширения данной процедуры на остальные эксгаустеры). Данная работа является рутинной(несложной, но долгой) - ее возможно завершить после дедлайна (определенных договоренностей)

# Установка

Скачайте репозиторий из
*GitHub: https://github.com/K-Team-Coders/Udarnik*

# Запуск приложения через Docker (В разработке)

ДЛЯ РАБОТЫ НЕОБХОДИМО ИСПОЛЬЗОВАНИЕ ПЕРЕМЕННЫХ ОКРУЖЕНИЯ ДЛЯ РАБОТЫ PostgreSQL, FastAPI, python-kafka

Откройте терминал в корне проекта, пропишите команду `docker-compose up -d`

Через некоторое время можно зайти в браузер по адресу *http://localhost:8080/*

# Запуск приложения вручную

Для универсальной работы приложения, были использованы возможности библиотеки **dotenv**

В корне проекта необходимо создать файл DB.env

Пример оформления:

`IP="192.168.0.131"   USER="temio"   PASSWORD="temio"   PORT="5433"   RUN_IP="192.168.0.156"   RUN_PORT="8079`

IP, User, Password, Port - Для подключения к PostgreSQL

Run_IP, Run_PORT - Для запуска FastAPI

#### Backend

Откройте терминал в папке ***backend***, выполните команды:

`python -m venv venv`

`venv\Scripts\activate`

`pip install -r requirements.txt`

Вы создали виртуальное окружение и загрузили необходимые библиотеки, теперь можно запустить backend-часть этого проекта

В папке backend, выполнить

`python backendFastApi.py runserver`

#### Frontend

Откройте терминал в папке ***frontend***, выполните команды:

`npm install`

`npm run serve`

После этого frontend-часть этого проекта будет доступна либо на http://localhost:8080/, либо на http://localhost:8081/

#### Database

Установите PostgreSQL v.=14

В pg_hba.conf при необходимости можно задать адреса, с которых аналитики будут брать данные, а также адреса по которым будут обращаться машины с поднятыми инстансами python-kafka, если, вы будете расширяться.

### Математическая составляющая проекта и почему это работает.

Так как данные поступают из Apache Kafka непрерывно, для их оптимального хранения и обработки было принято решение декомпозировать отношения в 4ю нормальную форму. Отношения, находящиеся в **4НФ** для данной задачи имеют вид:
**ID(Int, PK), Name(Text), Value(Double), Data(Timestamp without time zone)**.

Для реализации этого в PostgreSQL необходимо создать базу данных с одним отношением и четыремя атрибутами соотвественно.

Использование 4НФ позволяет получить преимущество в скорости вычислений для любых преобразований данных. То есть если нас интересует аналитика по одному конкретному сенсору, то мы делаем выборку с заранее заданным **Name.**
Если нас интересует анализ временных рядов, то мы осуществляем выборку по времени сообщения из Kafka.
И так далее.

### Задача предсказания времени поломки

В данной работе для прогноизирования поведения одного из датчиков (например SM_Exgauster[3:24]) была использована авторегрессионая модель. Принцип её работы заключатеся в разложение ряда на собственные значения в прошлом. Другими словами, наши признаки в модели обычной регрессии мы заменяем значениями той же переменной, но за предыдущие периоды.
Когда мы прогнозируем значение в период t с помощью данных за предыдущий период (AR(1)), уравнение будет выглядеть следующим образом.

$$
y_t = c + \varphi  \cdot y_{t-1}
$$

где c— это константа, $\varphi$— вес модели, yt–1 — значение в период t – 1.
Модель скользящего среднего (moving average, MA) помогает учесть случайные колебания или отклонения (ошибки) истинного значения от прогнозного. Можно также сказать, что модель скользящего среднего — это авторегрессия на ошибку. Конечным итогом стало сбор SARIMAX, которая использует предыдущие значения с использованием скользящего среднего и учитывающая сезонность (S),внешние или экзогенные факторы (eXogenous factors).
Примеры работы предскзаний вы можете увидеть в Jupyter ноутбуке или в скриншотах снизу:

![image](https://user-images.githubusercontent.com/80591614/219932750-3066a9c0-c38a-40ee-a9be-00aafe80f14c.png)
Первый график: Получение данных по временному срезу от одного датчика `<br />`
Второй график: Разбиение данных на обучающуюся и тестовую выборку с учетом последних изменений `<br />`
Третий график: Процесс обучения и получение предсказания поведения на 2 дня вперед `<br />`

## Презентация

Презентация доступна по ссылке

https://disk.yandex.ru/d/46HgM6p3FAwx7A

## Скринкаст

Скринкаст доступен по ссылке

https://disk.yandex.ru/d/y-PKHwv5D1mWxw

На нем в целях демонстрации были изменены поступающие значения в строке 199 файла backendFastApi.py
Эти значения проверяют попадания в границы, и цвет на стороне пользователя изменяется.

## API

Весь API представлен в файле **backendFastApi.py**.
## Скриншоты работы проекта
![photo_2023-02-19_09-51-16](https://user-images.githubusercontent.com/74972003/219933519-9069e30e-9aef-4ad4-b5a1-6c25eacb9970.jpg)
Общее окно состояний эксгаустеров 
![photo_2023-02-19_09-51-12](https://user-images.githubusercontent.com/74972003/219933524-e6acea57-6022-414d-8c62-c695f4381328.jpg)
Мнемоническая схема работы эксгаустера У-171 (№1) 
![photo_2023-02-19_09-51-06](https://user-images.githubusercontent.com/74972003/219933528-da6fdf3e-ed2b-498a-abd7-fa4fd025aa80.jpg)
Окно с графиками зависимостей значений датчиков от даты изменения
GET-запросы по адресам:

1) *http://RUN_IP:RUN_PORT/lastMnemonicEX1/*
2) *http://RUN_IP_RUN_PORT/lastGraphEX1/*

Приложение можно использовать в любых проектах, достаточно пробросить API к нужным вычислениям.
